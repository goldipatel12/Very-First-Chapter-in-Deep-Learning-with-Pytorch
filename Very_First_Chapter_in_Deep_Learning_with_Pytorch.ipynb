{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Very_First_Chapter_in_Deep_Learning_with_Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLt7UAxSc80P"
      },
      "source": [
        "#**Very First Chapter in Deep Learning with Pytorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdhnEvdYjUgi"
      },
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1s-try8jWbH_bZwr-36wpc9RPgRFc0wQh'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8J1zCmG9F71"
      },
      "source": [
        "#1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSFkGPeN97_H"
      },
      "source": [
        "##What are neural networks?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgt01UAq-C-a"
      },
      "source": [
        "As this tutorial is intended for complete beginners, so I will quickly explaining neural networks. It is my firm belief that you're going to learn the most by actually working with this technology, but I will be briefing so it can be useful to have a basic understanding going in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QrSzCSKCpHP"
      },
      "source": [
        "Neural networks at their core are just another tool in the set of machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY-45l73Cr8E"
      },
      "source": [
        "Neural networks consists of a bunch of \"neurons' which are values that start off as your input data, and then get multiplied by weights, summed together, and then passed through an activation function to produce new values, and this process then repeats over however many \"layers\" your neural network has to then produce an output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmOxz8GdFxy1"
      },
      "source": [
        "It looks something like :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs3i29mqlNj6"
      },
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1vn3O9SVy_z1CpheZIti7aRA0k6nKVmNJ'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl__rviUGV1G"
      },
      "source": [
        "The X1, X2, X3 are the \"features\" of your data. These could be pixel values of an image, or some other numerical characteristic that describes your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noeO4_EDGYvY"
      },
      "source": [
        "In your hidden layers (\"hidden\" just generally refers to the fact that the programmer doesn't really set or control the values to these layers, the machine does), these are neurons, numbering in however many you want (you control how many there are, just not the value of those neurons), and then they lead to an output layer. The output is usually either a single neuron for regression tasks, or as many neurons as you have classes. In the above case, there are 3 output neurons, so maybe this neural network is classifying dogs vs cats vs humans. Each neuron's value can be thought of as a confidence score for if the neural network thinks it's that class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_22rZVxGfcg"
      },
      "source": [
        "Whichever neuron has the highest value, that's the predicted class! So maybe the top of the three output neurons is \"human,\" then \"dog\" in the middle and then \"cat\" on the bottom. If the human value is the largest one, then that would be the prediction of the neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBFrrI4kGjAd"
      },
      "source": [
        "Connecting all of the neurons are those lines. Each of them is a weight, and possibly a bias. So the inputs get multiplied by the weights, the biases are added in, then it gets summed at the next neuron, passed through an activation function, to be the next input value for the next one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkpKLMEallAY"
      },
      "source": [
        "<img src = 'https://drive.google.com/uc?id=11Ut40yTXMVYJq-lrmgPTaDuzyh3FdfWv'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsu4P-dtHOki"
      },
      "source": [
        "Above is an example of this \"zoomed in\" so to speak to show the mechanism for just a single neuron. You can see the inputs from other neurons come in, they're multiplied by the weights, then they are summed together. After this summation, they pass through an activation function. The activation function's job is to calculate whether or not, or how much, a neuron is \"firing.\" A neuron could output a 0 or 1 to be off or on, but also, more commonly, could instead output a range between 0 and 1, for example, which serves as input to the next layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Njyo1iK1bZ"
      },
      "source": [
        "###How does a neural network \"learn?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqA6tAnvK7im"
      },
      "source": [
        "For now, we'll just consider the \"supervised learning\" approach, where the programmer shows the neural network the input data, and then also tells the machine what the output should be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWymYaikLBQc"
      },
      "source": [
        "Alright, you're basically an expert now. Let's get to Pytorch. If you're still confused about certain things, that's totally fine. Most, if not all, should be ironed out by actually working with this stuff."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BcT-HwjNCdp"
      },
      "source": [
        "##What is Pytorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfp3_wa5NroF"
      },
      "source": [
        "PyTorch is an open source machine learning library based on the Torch library, that does operations on tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g0nrB0ZN1gu"
      },
      "source": [
        "**Used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm_ed4joOKnl"
      },
      "source": [
        "###What's a tensor?!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkOGFfiISsIP"
      },
      "source": [
        "You can just think of a tensor like an array. Really all we're doing is basically multiplying arrays here. That's all there is to it. The fancy bits are when we run an optimization algorithm on all those weights to start modifying them. Neural networks themselves are actually super basic and simple. Their optimization is a little more challenging, but most of these deep learning libraries also help you a bit with that math. If you want to learn how to do everything yourself by hand, stay tuned later in the series. I just don't think it would be wise to lead with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXUQxdiCTJfw"
      },
      "source": [
        "So, let's poke with some tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSGf1l8M9Ec9",
        "outputId": "3fb9248d-6be3-442a-c2b0-32fde4de4925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.Tensor([5, 3])\n",
        "b = torch.tensor([2, 1])\n",
        "\n",
        "print(a*b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10.,  3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XnSSYPsUTRH"
      },
      "source": [
        "So yeah, it's just [5x2, 3x1]. Simple stuff!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKoBgfBOUpwv"
      },
      "source": [
        "Because it's a lot of operations on arrays, Pytorch aims to mimic the very popular numeric library in Python called NumPy. Many of the exact same methods exist, usually with the same names, but sometimes different ones. One common task is to make an \"empty\" array, of some shape. In NumPy, we use np.zeros. In Pytorch, we do the same!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz4jPAEHT5J2",
        "outputId": "480613b1-db15-4496-ff97-4281e1927407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "c = torch.zeros([2, 5])\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic2yEai1XkYJ",
        "outputId": "e8c91f26-3bd1-4ad7-9ee8-7d6434a8aeb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(c.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPthDvsMX7aJ"
      },
      "source": [
        "If you need to generate an array of random values, but a specific shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_-EbhGkXuKi",
        "outputId": "1f5cc0e2-3a6c-43e1-ad9c-c183cd1e8853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "d = torch.rand([2, 5])\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1484, 0.3180, 0.4266, 0.0962, 0.4779],\n",
            "        [0.1976, 0.3824, 0.7238, 0.2850, 0.6164]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0--9DIfOYlj5"
      },
      "source": [
        "And no, I am not wasting your time with any of these examples. We will be using all of these methods, and learning more along the way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgLqRDo-Ynj9"
      },
      "source": [
        "For the last one, how about a reshape? It turns out Pytorch decided to come up with a new name that no one else uses, they call it .view()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ebFS_v0Ytb5"
      },
      "source": [
        "So, in the above, we have 2 tensors, with 5 values in each. We could flatten this to be 1 tensor with 10 values. To do this, we would use .view():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtdkFkueYEt2",
        "outputId": "e98c6fe7-aab0-4910-ae15-4eb7b822587e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "d.view([1, 10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1484, 0.3180, 0.4266, 0.0962, 0.4779, 0.1976, 0.3824, 0.7238, 0.2850,\n",
              "         0.6164]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcCoo7NzZE97"
      },
      "source": [
        "I don't totally mind this naming convention. You're literally \"viewing\" that tensor as a 1x10 now. It doesn't actually modify the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeZdVOBXY3K4",
        "outputId": "d3864b0f-08ac-47ac-8b29-4f23d14b0005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1484, 0.3180, 0.4266, 0.0962, 0.4779],\n",
              "        [0.1976, 0.3824, 0.7238, 0.2850, 0.6164]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_e0AF3UZMRv"
      },
      "source": [
        "Of course you can re-assign:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv_HTWrjZIZ5"
      },
      "source": [
        "d = d.view([1, 10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihvpn1UHZUVJ",
        "outputId": "4bce1750-63af-463a-cdc0-dfb4fa6cb27d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1484, 0.3180, 0.4266, 0.0962, 0.4779, 0.1976, 0.3824, 0.7238, 0.2850,\n",
              "         0.6164]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLnt0_9nZdSS"
      },
      "source": [
        "So, this is the super fast introduction to Pytorch and neural network and now we will be working on the input to our neural network, the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldJAF_qNZ3Cq"
      },
      "source": [
        "One of the very few things that we have control over when it comes to neural networks is the data, and the format/structure of this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRneobzcZ68g"
      },
      "source": [
        "First we have to acquire that data, then we have to consider how to convert the data to numerical values, consider things like scaling, and then figure out how we will be showing this data to the neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT7Ee7FdaAfZ"
      },
      "source": [
        "#2. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ophFD8bVF0"
      },
      "source": [
        "##Neural Network Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mknmkeStbhvE"
      },
      "source": [
        "So now that you know the basics of what Pytorch is, let's apply it using a basic neural network example. The very first thing we have to consider is our data. In most tutorials, this bit is often overlooked in the interest of going straight to the training of a neural network. That said, as a programmer working with neural networks, one of your largest tasks is preprocessing your data and formatting it in such as way to be easiest for the neural network to work with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxvlY3npbi3k"
      },
      "source": [
        "First, we need a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb4AWe1AdO7v"
      },
      "source": [
        "We're just going to use data from Pytorch's \"torchvision.\" Pytorch has a relatively handy inclusion of a bunch of different datasets, including many for vision tasks, which is what *torchvision* is for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-V2owad1zh"
      },
      "source": [
        "We're going to first start off by using Torchvision because you should know it exists, plus it alleviates us the headache of dealing with datasets from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFgjDr8veIKz"
      },
      "source": [
        "That said, this is the probably the last time that we're going to do it this way. While it's nice to load and play with premade datasets, it's very rare that we get to do that in the real world, so it is essential that we learn how to start from a more raw dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W6P9B32efRs"
      },
      "source": [
        "For now though, we're just trying to learn about how to do a basic neural network in pytorch, so we'll use torchvision here, to load the MNIST dataset, which is a image-based dataset showing handwritten digits from 0-9, and your job is to write a neural network to classify them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwHJI1ENeg1i"
      },
      "source": [
        "To begin, let's make our imports and load in the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TziRhbWFZUwE"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "train = datasets.MNIST('', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "test = datasets.MNIST('', train=False, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbxp0ZDe_cU"
      },
      "source": [
        "Above, we're just loading in the dataset, shuffling it, and applying any transforms/pre-processing to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjv9hnN7fB6K"
      },
      "source": [
        "Next, we need to handle for how we're going to iterate over that dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVEsy0aaeosW"
      },
      "source": [
        "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3PYfyFIfNAA"
      },
      "source": [
        "You'll see later why this torchvision stuff is basically cheating! For now though, what have we done? Well, quite a bit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUwICVjfdAm"
      },
      "source": [
        "**Training and Testing data split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv88MewNfiJ7"
      },
      "source": [
        "To train any machine learning model, we want to first off have training and validation datasets. This is so we can use data that the machine has never seen before to \"test\" the machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cix2H90ffl2_"
      },
      "source": [
        "**Shuffling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U88nULr4qWH"
      },
      "source": [
        "Then, within our training dataset, we generally want to randomly shuffle the input data as much as possible to hopefully not have any patterns in the data that might throw the machine off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc5AxTZ64t8W"
      },
      "source": [
        "For example, if you fed the machine a bunch of images of zeros, the machine would learn to classify everything as zero. Then you'd start feeding it ones, and the machine would figure out pretty quick to classify everything as ones...and so on. Whenever you stop, the machine would probably just classify everything as the last thing you trained on. If you shuffle the data, your machine is much more likely to figure out what's what."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9o15tFq46mv"
      },
      "source": [
        "**Scaling and normalization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pNm25fj5m0M"
      },
      "source": [
        "Another consideration at some point in the pipeline is usually scaling/normalization of the dataset. In general, we want all input data to be between zero and one. Often many datasets will contain data in ranges that are not within this range, and we generally will want to come up with a way to scale the data to be within this range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9FNLTKR5pnB"
      },
      "source": [
        "For example, an image is comprised of pixel values, most often in the range of 0 to 255. To scale image data, you usually just divide by 255. That's it. Even though all features are just pixels, and all you do is divide by 255 before passing to the neural network, this makes a huge difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaBMnqC35rV-"
      },
      "source": [
        "**Batches**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsstbAXe5zuu"
      },
      "source": [
        "Once you've done all this, you then want to pass your training dataset to your neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T95IVDCpAKn2"
      },
      "source": [
        "Not so fast!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwjW7cEAWhI"
      },
      "source": [
        "There are two major reasons why you can't just go and pass your entire dataset at once to your neural network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFW7z9RyAafS"
      },
      "source": [
        "\n",
        "\n",
        "1.   Neural networks shine and outperform other machine learning techniques because of how well they work on big datasets. Gigabytes. Terabytes. Petabytes! When we're just learning, we tend to play with datasets smaller than a gigabyte, and we can often just toss the entire thing into the VRAM of our GPU or even more likely into RAM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_K_YJBgAeSO"
      },
      "source": [
        "Unfortunately, in practice, you would likely not get away with this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsyE_evqAgpF"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "2.   The aim with neural networks is to have the network generalize with the data. We want the neural network to actually learn general principles. That said, neural networks often have millions, or tens of millions, of parameters that they can tweak to do this. This means neural networks can also just memorize things. While we hope neural networks will generalize, they often learn to just memorize the input data. Our job as the scientist is to make it as hard as possible for the neural network to just memorize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB6QI8N_Ayil"
      },
      "source": [
        "This is another reason why we often track \"in sample\" validation acccuracy and \"out of sample\" validation accuracy. If these two numbers are similar, this is good. As they start to diverge (in sample usually goes up considerably while out of sample stays the same or drops), this usually means your neural network is starting to just memorize things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_m7gshOBBG0"
      },
      "source": [
        "One way we can help the neural network to not memorize is, at any given time, we feed only some specific batch size of data. This is often something between 8 and 64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW6eY9igBEKF"
      },
      "source": [
        "*Although there is no actual reason for it, it's a common trend in neural networks to use base 8 numbers for things like neuron counts, batch sizes...etc.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sz7RbikBLzH"
      },
      "source": [
        "This batching helps because, with each batch, the neural network does a back propagation for new, updated weights with hopes of decreasing that loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2O_WkrYBO0b"
      },
      "source": [
        "With one giant passing of your data, this would include neuron changes that had nothing to do with general principles and were just brute forcing the operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtae7zLgBQn_"
      },
      "source": [
        "By passing many batches, each with their own gradient calcs, loss, and backprop, this means each time the neural network optimizes things, it will sort of \"keep\" the changes that were actually useful, and erode the ones that were just basically memorizing the input data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax1f46etBVjS"
      },
      "source": [
        "Given a large enough neural network, however, even with batches, your network can still just simply memorize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCMmFazXBZ4L"
      },
      "source": [
        "This is also why we often try to make the smallest neural network as possible, so long as it still appears to be learning. In general, this will be a more successful model long term."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVKxf2HwBb70"
      },
      "source": [
        "**Now what?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByOAsUwIBkpW"
      },
      "source": [
        "Well, we have our data, but what is it really? How do we work with it? We can iterate over our data like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQGuqE1ifJJI",
        "outputId": "d449d586-47c9-414c-b6b0-d4dc1c549fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "source": [
        "for data in trainset:\n",
        "    print(data)\n",
        "    break"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([4, 4, 9, 8, 1, 6, 3, 2, 2, 6])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ymtW2hBw0S"
      },
      "source": [
        "Each iteration will contain a batch of 10 elements (that was the batch size we chose), and 10 classes. Let's just look at one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBMHZK3uBouM"
      },
      "source": [
        "X, y = data[0][0], data[1][0]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5D8jVieB3jI"
      },
      "source": [
        "X is our input data. The features. The thing we want to predict. y is our label. The classification. The thing we hope the neural network can learn to predict. We can see this by doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpsYY6BHB6YO"
      },
      "source": [
        "data[0] is a bunch of features for things and data[1] is all the targets. So:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIGTSyKRBzYQ",
        "outputId": "11ff770b-a4da-4882-dc81-bfb75d3b031b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(data[1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4, 4, 9, 8, 1, 6, 3, 2, 2, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwbexNOqCKs0"
      },
      "source": [
        "As you can see, data[1] is just a bunch of labels. So, since data[1][0] is a 2, we can expect data[0][0] to be an image of a 2. Let's see!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo1AMyfWB9WU",
        "outputId": "766493d3-50c1-4854-d165-eedbbc39310d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt  # pip install matplotlib\n",
        "\n",
        "plt.imshow(data[0][0].view(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6kZi_7iCTK4"
      },
      "source": [
        "Clearly a 0 indeed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUclFof4CZi9"
      },
      "source": [
        "So, for our checklist:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV0e5yu9Cb2Y"
      },
      "source": [
        "We've got our data of various featuresets and their respective classes.\n",
        "That data is all numerical.\n",
        "We've shuffled the data.\n",
        "We've split the data into training and testing groups.\n",
        "Is the data scaled?\n",
        "Is the data balanced?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0-HWgFMCeVp"
      },
      "source": [
        "Looks like we have a couple more questions to answer. First off is it scaled? Remember earlier I warned that the neural network likes data to be scaled between 0 and 1 or -1 and 1. Raw imagery data is usually RGB, where each pixel is a tuple of values of 0-255, which is a problem. 0 to 255 is not scaled. How about our dataset here? Is it 0-255? or is it scaled already for us? Let's check out some lines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtwPM3-uCNqN",
        "outputId": "002b5a9c-8cf4-4d40-9d58-e530c483eb28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "data[0][0][0][0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqshNeG1CqHZ"
      },
      "source": [
        "Hmm, it's empty. Makes sense, the first few rows are blank probably in a lot of images. The 2 up above certainly is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQX5hELNCsgZ",
        "outputId": "136f3e6e-abd7-4c2a-d7f1-ae7e9ebd3a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "data[0][0][0][7]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.5922, 0.9922, 0.8980, 0.0824, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.1059, 0.9529, 0.6275, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySXt8AsvFpt0"
      },
      "source": [
        "Ah okay, there we go, we can clearly see that... yep this image data is actually already scaled for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfVsEKGFq4J"
      },
      "source": [
        "... in the real world, it wont be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzqXYW_9FwYe"
      },
      "source": [
        "Like I said: Cheating! Hah. Alright. One more question: Is the data balanced?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3zpNscuJ45t"
      },
      "source": [
        "**What is data balancing?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A57lqiTTJ6yU"
      },
      "source": [
        "Recall before how I explained that if we don't shuffle our data, the machine will learn things like what the last few hundred classes were in a row, and probably just predict that from there on out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTXjEytbJ9fp"
      },
      "source": [
        "Well, with data balancing, a similar thing could occur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O63xunnXKNsr"
      },
      "source": [
        "Imagine you have a dataset of cats and dogs. 7200 images are dogs, and 1800 are cats. This is quite the imbalance. The classifier is highly likely to find out that it can very quickly and easily get to a 72% accuracy by simple always predicting dog. It is highly unlikely that the model will recover from something like this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOPRfDI5KQYO"
      },
      "source": [
        "Other times, the imbalance isn't quite as severe, but still enough to make the model almost always predict a certain way except in the most obvious-to-it-of cases. Anyway, it's best if we can balance the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckXhR6nDKSYE"
      },
      "source": [
        "By \"balance,\" I mean make sure there are the same number of examples for each classifications in training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgdSPgpYKUe7"
      },
      "source": [
        "Sometimes, this simply isn't possible. There are ways for us to handle for this with special class weighting for the optimizer to take note of, but, even this doesn't always work. Personally, I've never had success with this in any real world application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwIIoLtoKXTm"
      },
      "source": [
        "In our case, how might we confirm the balance of data? Well, we just need to iterate over everything and make a count. Pretty simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRKMv1WXJ4Nz",
        "outputId": "41478319-0d7e-4f72-8e82-fe8d1b05bd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "total = 0\n",
        "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
        "\n",
        "\n",
        "for data in trainset:\n",
        "    Xs, ys = data\n",
        "    for y in ys:\n",
        "        counter_dict[int(y)] += 1\n",
        "        total += 1\n",
        "\n",
        "print(counter_dict)\n",
        "\n",
        "for i in counter_dict:\n",
        "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
            "0: 9.871666666666666%\n",
            "1: 11.236666666666666%\n",
            "2: 9.93%\n",
            "3: 10.218333333333334%\n",
            "4: 9.736666666666666%\n",
            "5: 9.035%\n",
            "6: 9.863333333333333%\n",
            "7: 10.441666666666666%\n",
            "8: 9.751666666666667%\n",
            "9: 9.915000000000001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5jUrTMTKk20"
      },
      "source": [
        "I am sure there's a better way to do this, and there might be a built-in way to do it with torchvision. Anyway, as you can see, the lowest percentage is 9% and the highest is just over 11%. This should be just fine. We could balance this perfectly, but there's likely no need for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acVsspFhKoWg"
      },
      "source": [
        "I'd say we're ready for passing it through a neural network, which is what we'll be doing in the next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5euXpZcK7g_"
      },
      "source": [
        "#Building our Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcSL9Kq3LQbc"
      },
      "source": [
        "##Creating a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccBA4KfmLXCS"
      },
      "source": [
        "From now onwards we're going to focus on actually creating a neural network. Untill here, we went over the following code for getting our data setup:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIdEXC4fCu2n"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "train = datasets.MNIST('', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "test = datasets.MNIST('', train=False, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVquPRACLn5e"
      },
      "source": [
        "Now, let's actually create our neural network model. To begin, we're going to make a couple of imports from Pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPcL-DsPLxsC"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDP5DCc7L2pZ"
      },
      "source": [
        "The torch.nn import gives us access to some helpful neural network things, such as various neural network layer types (things like regular fully-connected layers, convolutional layers (for imagery), recurrent layers...etc). For now, we've only spoken about fully-connected layers, so we will just be using those for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5GSVwbL4zv"
      },
      "source": [
        "The torch.nn.functional area specifically gives us access to some handy functions that we might not want to write ourselves. We will be using the relu or \"rectified linear\" activation function for our neurons. Instead of writing all of the code for these things, we can just import them, since these are things everyone will be needing in their deep learning code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URJtr1c-MCJz"
      },
      "source": [
        "This is something you can call the Advantage of using Built in Libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh1pHvt6MOTj"
      },
      "source": [
        "To make our model, we're going to create a class. We'll call this class net and this net will inhereit from the nn.Module class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaQgvYUtL0VZ",
        "outputId": "5b4ea9d1-26e9-403d-8af8-e7f4aa5d8aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_pyS72MMmBK"
      },
      "source": [
        "Nothing much special here, but I know some people might be confused about the init method. Typically, when you inherit from a parent class, that init method doesn't actually get run. This is how we can run that init method of the parent class, which can sometimes be required...because we actually want to initialize things! For example, let's show some classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9kdn--qMVWw",
        "outputId": "ed98d008-b60b-4061-ca6a-f2e9b395a0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "class a:\n",
        "    '''Will be a parent class'''\n",
        "    def __init__(self):\n",
        "        print(\"initializing a\")\n",
        "\n",
        "class b(a):\n",
        "    '''Inherits from a, but does not run a's init method '''\n",
        "    def __init__(self):\n",
        "        print(\"initializing b\")\n",
        "\n",
        "class c(a):\n",
        "    '''Inhereits from a, but DOES run a's init method'''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"initializing c\")\n",
        "\n",
        "b_ob = b()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initializing b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Baa-B4QGNLOF"
      },
      "source": [
        "Notice how our b_ob doesn't have the a class init method run. If we create a c_ob from the c class though:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmCgWw_IMx_N",
        "outputId": "bff9b5ed-6660-4180-b384-d6c0c55fad9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "c_ob = c()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initializing a\n",
            "initializing c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPgfjZY9NQod"
      },
      "source": [
        "Both init methods are run. Yay. Okay back to neural networks. Let's define our layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmV7Z2x5NN93"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dvz8gkoNbyh"
      },
      "source": [
        "All we're doing is just defining values for some layers, we're calling them fc1, fc2...etc, but you could call them whatever you wanted. The fc just stands for fully connected. Fully connected refers to the point that every neuron in this layer is going to be fully connected to attaching neurons. Nothing fancy going on here! Recall, each \"connection\" comes with weights and possibly biases, so each connection is a \"parameter\" for the neural network to play with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ip1lHH5Nd8F"
      },
      "source": [
        "In our case, we have 4 layers. Each of our nn.Linear layers expects the first parameter to be the input size, and the 2nd parameter is the output size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Xa1t0gNgM1"
      },
      "source": [
        "So, our first layer takes in 28x28, because our images are 28x28 images of hand-drawn digits. A basic neural network is going to expect to have a flattened array, so not a 28x28, but instead a 1x784."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1CeweZONif6"
      },
      "source": [
        "Then this outputs 64 connections. This means the next layer, fc2 takes in 64 (the next layer is always going to accept however many connections the previous layer outputs). From here, this layer ouputs 64, then fc3 just does the same thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYUUEk2_Np6L"
      },
      "source": [
        "fc4 takes in 64, but outputs 10. Why 10? Our \"output\" layer needs 10 neurons. Why 10 neurons? We have 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86gt3ij7NwXC"
      },
      "source": [
        "Now, that's great, we have those layers, but nothing really dictating how they interact with eachother, they're just simply defined."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PrZ-ix9NyXc"
      },
      "source": [
        "The simplest neural network is fully connected, and feed-forward, meaning we go from input to output. In one side and out the other in a \"forward\" manner. We do not have to do this, but, for this model, we will. So let's define a new method for this network called forward and then dictate how our data will pass through this model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbUUQeBRNUgH",
        "outputId": "8aa3a12e-8724-4f5b-b494-d4e33d1f859f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKKSDk-fN7Q9"
      },
      "source": [
        "Notice the x is a parameter for the forward method. This will be our input data. As you can see, we literally just \"pass\" this data through the layers. This could in theory learn with some problems, but this is going to most likely cause some serious explosions in values. The neural network could control this, but probably wont. Instead, what we're missing is an activation function for the layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdEekyyeN9b_"
      },
      "source": [
        "Recall that we're mimicking brain neurons that either are firing, or not. We use activation functions to take the sum of the input data * weights, and then to determine if the neuron is firing or not. Initially, these were often step functions that were literally either 0 or 1, but then we found that sigmoids and other types of functions were better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFjH-zT2N_Nx"
      },
      "source": [
        "Currently, the most popular is the rectified linear, or relu, activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLZM7-ouOD90"
      },
      "source": [
        "Basically, these activation functions are keeping our data scaled between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ3KHPc7OIX2"
      },
      "source": [
        "Finally, for the output layer, we're going to use softmax. Softmax makes sense to use for a multi-class problem, where each thing can only be one class or the other. This means the outputs themselves are a confidence score, adding up to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1sJjsgwN1Ag",
        "outputId": "79603d52-c3c2-45e7-8512-7c0d8b3bba90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogfq5O7LOxay"
      },
      "source": [
        "At this point, we've got a neural network that we can actually pass data to, and it will give us an output. Let's see. Let's just create a random image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVuZgigWOpsO"
      },
      "source": [
        "X = torch.randn((28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JahGHRecO3jb"
      },
      "source": [
        "So this is like our images, a 28x28 tensor (array) of values ranging from 0 to 1. Our neural network wants this to be flattened, however so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcF1g_k-O1e9"
      },
      "source": [
        "X = X.view(-1,28*28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r07-x7PMPJIp"
      },
      "source": [
        "You should understand the 28*28 part, but why the leading -1?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApuqYIqwPMp6"
      },
      "source": [
        "Any input and output to our neural network is expected to be a group feature sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3-GFawiPy_I"
      },
      "source": [
        "Even if you intend to just pass 1 set of features, you still have to pass it as a \"list\" of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0T997BUP1Qk"
      },
      "source": [
        "In our case, we really just want a 1x784, and we could say that, but you will more often is -1 used in these shapings. Why? -1 suggests \"any size\". So it could be 1, 12, 92, 15295...etc. It's a handy way for that bit to be variable. In this case, the variable part is how many \"samples\" we'll pass through."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wmsLCqAPAPn"
      },
      "source": [
        "output = net(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUYLpmxMQ5lE"
      },
      "source": [
        "What should we be expecting the output to be? It should be a tensor that contains a tensor of our 10 possible classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ0T3TVtQ3tG",
        "outputId": "9d1f38c4-351d-4986-c0c6-274aa8bf282c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2390, -2.2514, -2.2302, -2.3744, -2.3137, -2.4241, -2.3855, -2.2833,\n",
              "         -2.1833, -2.3697]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_YGlbLbRFZS"
      },
      "source": [
        "Great. Looks like the forward pass works and everything is as expected. Why was it a tensor in a tensor? Because input and output needs to be variable. Even if we just want to predict on one input, it needs to be a list of inputs and the output will be a list of outputs. Not really a list, it's a tensor, but hopefully you understand what I mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2G_4DiwRPvP"
      },
      "source": [
        "Of course, those outputs are pretty worthless to us. Instead, we want to iterate over our dataset as well as do our backpropagation, which is what we'll be getting into now onwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5XHnfmDRZBm"
      },
      "source": [
        "#4. Training Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q80_PmgvSAhT"
      },
      "source": [
        "##Training our Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMEJNMMgTdP-"
      },
      "source": [
        "Untill now, we created the code for our neural network. Now, we'll be actually training this neural network by learning how to iterate over our data, pass to the model, calculate loss from the result, and then do backpropagation to slowly fit our model to the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGf1eiguTnnq"
      },
      "source": [
        "Code up to this point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4nPu9uCQ8wp",
        "outputId": "74dbf519-0f8d-4bd3-da57-4dabcf2dc960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train = datasets.MNIST('', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "test = datasets.MNIST('', train=False, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkwYanu5UP5x"
      },
      "source": [
        "Luckily for us, the \"data\" that we're using from Pytorch is actually nice fancy object that is making life easy for us at the moment. It's already in pretty batches and we just need to iterate over it. Next, we want to calculate loss and specify our optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtkYjLcuUL5N"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4IPUP9IUkpq"
      },
      "source": [
        "Our *loss_function* is what calculates \"how far off\" our classifications are from reality. As humans, we tend to think of things in terms of either right, or wrong. With a neural network, and arguably humans too, our accuracy is actually some sort of scaling score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyKuiYn3U6Gt"
      },
      "source": [
        "For example, you might be highly confident that something is the case, but you are wrong. Compare this to a time when you really aren't certain either way, but maybe think something, but are wrong. In these cases, the degree to which you're wrong doesn't matter in terms of the choice necessarily, but in terms of you learning, it does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Cld6TmU77S"
      },
      "source": [
        "In terms of a machine learning by tweaking lots of little parameters to slowly get closer and closer to fitting, it definitely matters how wrong things are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMJrT-U_U9c-"
      },
      "source": [
        "For this, we use loss, which is a measurement of how far off the neural network is from the targeted output. There are a few types of loss calculations. A popular one is mean squared error, but we're trying to use these scalar-valued classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg37TZaTVAHX"
      },
      "source": [
        "In general, you're going to have two types of classes. One will just be a scalar value, the other is what's called a one_hot array/vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixeSfU8aVCoZ"
      },
      "source": [
        "In our case, a zero might be classified as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7_QJZS4VENi"
      },
      "source": [
        "0 or [1, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muQDVSDfVO9z"
      },
      "source": [
        "[1, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0] is a one_hot array where quite literally one element only is a 1 and the rest are zero. The index that is hot is the classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_KOomNNVQ_t"
      },
      "source": [
        "A one_hot vector for a a 3 would be:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz6K-hpbVUmN"
      },
      "source": [
        "[0, 0, 0, 1, 0, 0, 0 ,0 ,0 ,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b72NzeHqVWzH"
      },
      "source": [
        "I tend to use one_hot, but this data is specifying a scalar class, so 0, or 1, or 2...and so on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb3v58NBViPA"
      },
      "source": [
        "Depending on what your targets look like, you will need a specific loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BHtLsv3VkEg"
      },
      "source": [
        "For one_hot vectors, I tend to use mean squared error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_zAps3ZVl57"
      },
      "source": [
        "For these scalar classifications, I use cross entropy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bqcN5flVngS"
      },
      "source": [
        "Next, we have our optimizer. This is the thing that adjusts our model's adjustable parameters like the weights, to slowly, over time, fit our data. I am going to have us using Adam, which is Adaptive Momentum. This is the standard go-to optimizer usually. There's a new one called rectified adam that is gaining steam. I haven't had the chance yet to make use of that in any project, and I do not think it's available as just an importable function in Pytorch yet, but keep your eyes peeled for it! For now, Adam will do just fine I'm sure. The other thing here is lr, which is the learning rate. A good number to start with here is 0.001 or 1e-3. The learning rate dictates the magnitude of changes that the optimizer can make at a time. Thus, the larger the LR, the quicker the model can learn, but also you might find that the steps you allow the optimizer to make are actually too big and the optimizer gets stuck bouncing around rather than improving. Too small, and the model can take much longer to learn as well as also possibly getting stuck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0J8rkHfVzgv"
      },
      "source": [
        "Imagine the learning rate as the \"size of steps\" that the optimizer can take as it searches for the bottom of a mountain, where the path to the bottom isn't necessarily a simple straight path down. Here's some lovely imagery to help explain learning rate:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xE4r4tImZpl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG30dU7omZ-2"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1jJD_XqqMxdn3fNZyBgb0Tkb_OXKJO9zF'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naXo3Qs-muVe"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1Ul8AneETcAeytRIFDEqDoSX04hy3FEhw'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd_a2sNDV3JJ"
      },
      "source": [
        "The black line is the \"path\" to the bottom of the optimization curve. When it comes to optimizing, sometimes you have to get worse in order to actually get beyond some local optimum. The optimizer doesn't know what the absolute best spot could be, it just takes steps to see if it can find it. Thus, as you can see in the image, if the steps are too big, it will never get to the lower points. If the steps are too small (learning rate too small), it can get stuck as well long before it reaches a bottom. The goal is for something more like:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGDCbFm7m7WY"
      },
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1hxSn0udrO4Y2C7Vrb8xnBxxv7dmaJz6E'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OGPF1SpWCYI"
      },
      "source": [
        "For simpler tasks, a learning rate of 0.001 usually is more than fine. For more complex tasks, you will see a learning rate with what's called a decay. Basically you start the learning rate at something like 0.001, or 0.01...etc, and then over time, that learning rate gets smaller and smaller. The idea being you can initially train fast, and slowly take smaller steps, hopefully getthing the best of both worlds:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqOxg0jcnH4A"
      },
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1rG8YGoV3RyPkgL1XEWYoWK5x62x5tQWY'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RKN_S1NWJpU"
      },
      "source": [
        "More on learning rates and decay later. For now, 0.001 will work just fine, and you just need to think of learning rate as what it sounds like: How quickly should we try to get this optimizer to optimize things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy4JB36MXpwO"
      },
      "source": [
        "Now we can iterate over our data. In general, you will make more than just 1 pass through your entire training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV2QbOhjXsL1"
      },
      "source": [
        "Each full pass through your dataset is referred to as an epoch. In general, you will probably have somewhere between 3 and 10 epochs, but there's no hard rule here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmmm5dAPXxiJ"
      },
      "source": [
        "Too few epochs, and your model wont learn everything it could have.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS4hHbQCX1NC"
      },
      "source": [
        "Too many epochs and your model will over fit to your in-sample data (basically memorize the in-sample data, and perform poorly on out of sample data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgsv94LxX3xQ"
      },
      "source": [
        "Let's go with 3 epochs for now. So we will loop over epochs, and each epoch will loop over our data. Something like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8kqurUvUWO-",
        "outputId": "c25ec78a-433a-4cc0-c7b9-80ab050b01bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "for epoch in range(3): # 3 full passes over the data\n",
        "    for data in trainset:  # `data` is a batch of data\n",
        "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
        "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
        "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
        "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
        "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
        "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
        "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0095, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T--6f6aEbGio"
      },
      "source": [
        "Every line here is commented, but the concept of gradients might not be clear. Once we pass data through our neural network, getting an output, we can compare that output to the desired output. With this, we can compute the gradients for each parameter, which our optimizer (Adam, SGD...etc) uses as information for updating weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-fdWHwWbI9F"
      },
      "source": [
        "This is why it's important to do a *net.zero_grad()* for every step, otherwise these gradients will add up for every pass, and then we'll be re-optimizing for previous gradients that we already optimized for. There could be times when you intend to have the gradients sum per pass, like maybe you have a batch of 10, but you want to optimize per 50 or something. I don't think people really do that, but the idea of Pytorch is to let you do whatever you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3Z1658BbNwU"
      },
      "source": [
        "So, for each epoch, and for each batch in our dataset, what do we do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ4cPa33bUxY"
      },
      "source": [
        "Grab the features (X) and labels (y) from current batch\n",
        "Zero the gradients (net.zero_grad)\n",
        "Pass the data through the network\n",
        "Calculate the loss\n",
        "Adjust weights in the network with the hopes of decreasing loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Gr3dP1bXTP"
      },
      "source": [
        "As we iterate, we get loss, which is an important metric, but we care about accuracy. So, how did we do? To test this, all we need to do is iterate over our test set, measuring for correctness by comparing output to target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ck3OdOnX8lI",
        "outputId": "311ef3bb-12f4-4a69-b8ab-6df98b403b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testset:\n",
        "        X, y = data\n",
        "        output = net(X.view(-1,784))\n",
        "        #print(output)\n",
        "        for idx, i in enumerate(output):\n",
        "            #print(torch.argmax(i), y[idx])\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PcX2Aplbc09"
      },
      "source": [
        "Yeah, I would say we did alright there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbxeczcZbapj",
        "outputId": "8d39a01d-d8c9-4c05-cc00-8680676423cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X[0].view(28,28))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7D-_98PbfGi",
        "outputId": "c0d439b9-c18b-43da-b426-8939438dc6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(torch.argmax(net(X[0].view(-1,784))[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuygXMLNbpbV"
      },
      "source": [
        "The above might be slightly confusing. I'll break it down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLmREP1Xbmx5",
        "outputId": "001e16ed-657a-485b-ae81-57146d6fab8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "a_featureset = X[0]\n",
        "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
        "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
        "first_pred = output[0]\n",
        "print(first_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.9305e+01, -1.2716e+01, -8.1812e+00, -6.3359e+00, -1.8744e+01,\n",
            "        -2.2179e+01, -2.9998e+01, -2.0695e-03, -1.4146e+01, -1.1324e+01],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDxRyUxsb0Tv"
      },
      "source": [
        "Which index value is the greatest? We use argmax to find this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb4uOqgKbsCn",
        "outputId": "f20e7020-01a8-48c3-a3b7-c162dec0461b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "biggest_index = torch.argmax(first_pred)\n",
        "print(biggest_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz2WBhdjcrDR"
      },
      "source": [
        "As fun and easy as it is to use a pre-made dataset, one of the first things you really want to do once you learn deep learning is actually do something you're interested in, which often means your own dataset that isn't prepared for us like this one was."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ2hCZHwcr_O"
      },
      "source": [
        "**So, This is my Very First Chapter in Deep Learning with PyTorch, hope you Liked It**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWRC7zoIb3cH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}